Please update the code so that the search_results.html contains links that when
clicked, open to the part of the file that contains the results.
```
import re
from collections import defaultdict
from pathlib import Path
import webbrowser
import multiprocessing

# Define a set of common words to ignore during search
stop_words = {"the", "and", "or", "an", "a", "in", "of", "to", "is", "for", "that", "it", "with", "on", "by", "this", "be", "as", "at", "from"}

# Define the path and name of the index file
index_path = "index_data.txt"

# Remove stop words from text
def remove_stop_words(text):
    words = re.findall(r"\w+", text.lower())
    return " ".join(word for word in words if word not in stop_words)

# Index a file
def index_file(path):
    index = defaultdict(set)
    with open(path, "r") as file:
        contents = file.read()
        words = re.findall(r"\w+", contents.lower())
        for word in words:
            index[word].add(str(path))
    return index

# Index the files in the directory using multiple processes
def index_files(directory):
    index = defaultdict(set)
    pool = multiprocessing.Pool()
    paths = (str(path) for path in Path(directory).rglob('*.txt'))
    results = pool.map(index_file, paths)
    pool.close()
    for result in results:
        for word in result:
            index[word] |= result[word]
    return index

# Read the index file
def read_index(directory):
    index = defaultdict(set)
    index_file_path = Path(directory) / index_path
    if index_file_path.exists():
        with open(index_file_path, "r") as file:
            for line in file:
                word, paths = line.rstrip().split(" ", 1)
                index[word] |= set(paths.split())
        return index
    else:
        print("Index not found.")
        choice = input("Do you want to create an index? (Y/N): ").lower()
        if choice == "y":
            create_index(directory)
            return read_index(directory)
        else:
            exit()

# Create the index file
def create_index(directory, force=False):
    index = index_files(directory)
    index_file_path = Path(directory) / index_path
    if force or not index_file_path.exists():
        with open(index_file_path, "w") as file:
            for word in index:
                file.write(word + " " + " ".join(index[word]) + "\n")
        print("Index created successfully!")
    else:
        print("Index file already exists. Use --force option to overwrite.")

# Search the indexed files and create the HTML page
def search_and_display_files(index, query):
    results = defaultdict(byte)
    words = re.findall(r"\w+", query.lower())
    for word in words:
        if word not in stop_words and word in index:
            for path in index[word]:
                results[path] += 1
                if results[path] >= 255:
                    # Stop counting this path if it already has 255 matches
                    break
    matches = []
    for path, count in sorted(results.items(), key=lambda item: -item[1])[:10]:
        with open(path, "r") as file:
            contents = file.read()
            excerpt = ""
            for word in words:
                # Find all occurrences of the word in the contents
                for match in re.findall(word, contents.lower()):
                    # Extract a substring containing the word and its surrounding context
                    pos = contents.lower().find(match)
                    excerpt += "... " + contents[max(0, pos-20):pos+len(word)+20] + " ..."
            if excerpt:
                # Add hyperlinks to the matched text
                contents_with_links = re.sub(fr"\b({'|'.join(map(re.escape, words))})\b", r'<a href="file://{}\#char=\g<1>">\g<1></a>', contents, flags=re.IGNORECASE)
                matches.append((count, excerpt, path, contents_with_links))
    if matches:
        print("Matching files found:")
        html = "<html><head><title>Search Results</title></head><body>"
        for i, match in enumerate(matches, start=1):
            html += f"<p>Match {i}: {match[1]}<br>Path: <a href=\"file://{match[2]}\">{match[2]}</a></p>"
            html += f"<pre>{match[3]}</pre>"
        html += "</body></html>"
        with open("search_results.html", "w") as file:
            file.write(html)
        webbrowser.open_new_tab("search_results.html")
    else:
        print("No matches.")

# Main program loop
if __name__ == "__main__":
    directory = input("Enter the directory containing the text files: ")
    index = read_index(directory)
    while True:
        query = input("Enter the search query: ")
        search_and_display_files(index, query)
        choice = input("Do you want to re-index the files? (Y/N): ").lower()
        if choice == "y":
            force = input("Do you want to overwrite the existing index? (Y/N): ").lower() == "y"
            create_index(directory, force)
            index = read_index(directory)
```



import os
import re

def sanitize_and_rename_files(directory_path):
    for root, _, files in os.walk(directory_path):
        for filename in files:
            original_filepath = os.path.join(root, filename)
            sanitized_filename = re.sub(r'[\\/:*?"<>|()\s]', '_', filename.lower())
            new_filepath = os.path.join(root, sanitized_filename)
            
            if original_filepath != new_filepath:
                os.rename(original_filepath, new_filepath)

directory_path = '/path/to/your/directory'
sanitize_and_rename_files(directory_path)


import os
import argparse

def get_size_summary(directory_path):
    """
    Get the summary of sizes for directories and files in the specified directory.

    Args:
        directory_path (str): The path of the directory to analyze.

    Returns:
        dict: A dictionary containing the summary of sizes for directories and files.
    """
    directory_sizes = {}
    for root, _, files in os.walk(directory_path):
        dir_size = sum(os.path.getsize(os.path.join(root, file)) for file in files)
        directory_sizes[root] = dir_size
    return directory_sizes

def main():
    """
    Command-line program to get the summary of sizes for directories and files.
    """
    parser = argparse.ArgumentParser(description='Get summary of directory and file sizes.')
    parser.add_argument('directory', type=str, help='The path to the directory to analyze.')
    args = parser.parse_args()

    directory_path = args.directory
    summary = get_size_summary(directory_path)

    print("Summary of directory and file sizes:")
    for path, size in summary.items():
        print(f"{path}: {size} bytes")

if __name__ == "__main__":
    main()



